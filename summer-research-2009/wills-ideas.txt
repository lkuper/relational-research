May 26, 2009:

Will's ideas for summer research
--------------------------------

1) Tabling and constraints, combined.  Tabling is a form of
memoization for logic programming that can not only make logic
programs more efficient, it can also prevent divergence!  What kind of
constraints?  Disequality constraints; "does not occur in" constraints
from nominal logic; pairo, et cetera.  (The only kind of constraint
that *does* work with tabling right now is unification.)  Gopal Gupta
is working on this, and Will considers it "not hard enough to be worth
a Ph.D., but hard enough to be worth a paper."

2) Relational encoding of polymorphic let for our relational type
inferencer.  Right now, we don't have a Hindley-Milner type inferencer
that supports polymorphic let, and in order to do this correctly, we
need something like copy-term, but copy-term is not declarative.  (But
if we use clever tagging and encoding of terms, we know we're able to
eliminate copy-term in some cases.)  Will thinks that, in addition to
that, we need perhaps some new kind of constraint or some other new
technique.  "An easy problem to understand."

3) Implement constraint logic programming over some domain, such as
FD, Z, Q, R, intervals.

4) Prove interesting properties of walk, such as termination.  "We
have at least three terminating versions of walk.  We're sure they
terminate; we just need to formalize a proof."

5) Prove correctness of triangular nominal unification.  The
correctness of nominal unification using idempotent substitutions has
already been shown.  This must be a bigger problem than proving the
correctness of triangular *regular* unification.  But, according to
Will, it's probably not an incredibly hard problem.

6) Write smart macros that perform optimizations.  For instance, in
lambdae and matche, a comma in a pattern means that the first
occurrence of that variable is fresh.  This information is useful!

7) intuitionistic implication (skipping)

8) Extend the relational arithmetic system from TRS to handle rational
numbers.  The interesting part of this would be figuring out how
bounds on term sizes would have to change to ensure finite failure of
individual goals.

9) revisit relational arithmetic system using tabling,
diseq. constraints, constraints on term size, etc. (skipping)

10) encode Presburger arithmetic using FSM approach (skipping)

11) implement a proof assistant based on alphaLeanTAP (skipping)

12) *Efficiently* implement true commutative conjunction!  You can
easily implement commutative disjunction using a complete search
strategy.  But conjunction isn't commutative -- if you swap two goals,
you may get failure where you had success before.  Of course, you
could implement this correctly but inefficiently, but we want
efficiency.

13) Do "fake" efficient commutative conjunction using a combination of
continuations, interleaving search, and tabling.  (Dan: "Unification
is adding knowledge, and it doesn't matter where or when you add that
knowledge.")  It's possible that coroutines (which are a lot like
generators) could be useful here.

14) Add coinductive logic programming to miniKanren.  Supposedly, this
is straightforward, because we already have an implementation of
tabling.  How this interacts with tabling and constraints is another
question.  Will: "When you have a tabling system, the question is: how
do you know when a call is a variant of an already-made call?"  Right
now, we use reification.  But in coinductive logic programming, you do
it with unification, which prompts the question: are there other
definitions of "variant call" which lead to other flavors of logic
programming?

15) Gupta's "Holy Grail": combine all of the desirable features of a
relational programming language in the same system at the same time.
Questions like: how does CLP interact with coinduction?  Does that
even make sense?  There's nothing like Haskell's separation-of-worlds
in logic programming, and this is something that could change the
field of logic programming.

16) Create a useful parallel implementation of miniKanren.  We already
have two parallel implementations of mK, but both are slower than
sequential mK.  Why?  Granularity analysis would help.  If we have (==
x 5) as a base case, the overhead of sending this single unification
to a new core or processor is more expensive than just performing the
unification.  Lots of interesting work here!

17) Extensions to our current implementation of nominal logic
programming: name inequality constraints, as in MLSOS; add disequality
constraints as in miniKanren; equivariant unification (a
generalization of unification that's NP-complete); replace noms
with variables; an "occurs-free" (staleness) constraint; et cetera.

18) What's the relationship between nominal logic and hygienic macros?
It seems like there's an interesting correspondence in the way they
both deal with avoiding variable capture.  Can we describe/implement
the full syntax-rules macro system in alphaKanren?  Dave Herman and
Mitch Wand worked on typed macros in Scheme -- check out Dave's blog.

19) Which SOS rules or side conditions can we not easily express?
Exploring this may result in new constraints and other language
extensions.  Start with TAPL.

20) Which Scheme/Prolog/Curry programs can we not express
satisfactorily in miniKanren?

21) Is there a relational equivalent of residuation?  

22) Revisit purely functional data structures for representing
substitutions (Aziz has a trie representation of substitutions).  We'd
like a purely functional data structure that has fast lookup *and*
lets us implement disequality constraints inefficiently.

23) Higher-order unification: unification based on beta-equivalence
rather than alpha-equivalence.  This would subsume nominal logic.
(Recall that beta equivalence means that ((lambda (x) x) y) is
equivalent to y.)

24) Add support for non-standard logics to miniKanren (temporal logic,
linear logic, modal logic, etc.)

25) Purely relational data structures: data structures that work well
with purely relational programming.  In relational programming, we
really care about the data structures we're using because unification
is your only tool, so, for instance, you need fancy data structures
even to represent *numbers*.  An example of a relational data
structure is a difference list.  (One idea: start with the Purely
Functional Data Structures book (Chris Okasaki) and see what's
runnable backwards.)  

26) Design patterns and idioms for relational programming.  This will
require clear definitions of relational, declarative, logic, and
functional programming.  Dan: "Functional programming is like logical
programming where all the arguments are ground."  Will: "Logic
programming is proof search, and functional programming is proof
reduction."

27) Implement a useful 'append' constraint -- a constraint that delays
appending two lists.

28) Add types to miniKanren.  Lots of people (like Stevie Strickland)
have added types to Scheme.  There's also something called "gradual
typing", which involves optional type annotations and a way to assign
blame for errors, and the YAP Prolog implementors have a paper about
it, but it's clear they don't know about the work that's been done in
Scheme with gradual typing so far.

29) Investigate relationship between monads and relational programming
(skipped)

30) Explore similarities between relations, macros, and term
rewriting (skipped)

31) Encode the pi-calculus in miniKanren.

32) Revisit the delarative copy-term issue, formalizing the approach
used in the alphaKanren paper.

33) Investigate the relationship between higher-order contracts and
relational programming.

34) Create an automatic scheme-to-miniKanren translation portal.

35) Develop a theory of how to derive bounds on term sizes in the
relational arithmetic system, and write a tool to help programmers
create goals with bounds on the size of terms.  Find a way to enforce
bounds simultaneously.  "The goal should be to allow mere mortals to
write relations like Logo."

36) According to Amr, Haskell type classes can be used to encode logic
programming!  What does that even mean?  This might be interesting.

37) Express dependent types in miniKanren -- this is Dan's idea.  Dan
says that when we do computing, we do intuitionistic logic, which
doesn't have exists and forall.  But when you move to dependent types,
you get an intuitionistic forall.  We don't really know what that
means.  We'd like to understand it well enough to add it to
miniKanren.  "Practical Dependent Types" is an interesting
dissertation that might be worth reading if we want to investigate this.

38) Mathematically characterize our interleaving search.  We don't
know how to formally characterize how our search produces answers.
Complicating matters is the fact that we have one implementation that
uses streams and one that uses continuations, and we'd like it if they
worked identically.

39) Avoid full occurs-check using recent insights.

40) Path compression with walk.

41) Applications for a second edition of TRS: a metacircular
interpreter (Dan says: "When you go to do this, you may say 'Gosh, I
wish I had constraint so-and-so', which could be the real value of the
project"); a program to generate all and only well-typed terms in the
calculus of constructions; parsing and composition semantics.

42) Implement functional logic programming using narrowing, as in
Curry.

43) Revisit Jiho's work on streams.  Suppose we have two mutually
recursive equations that define streams, say, the Thue-Morse sequence:
x = 0 . zip(y, x) and y = 1 . zip(x, y) where . is the concatenation
operator.  Jiho says, "This is a very pathological and beautiful
sequence."  Will says he "hamfistedly" did something with this long
ago, and it might be a good time to try again, since we have some new
tools and ideas: tabling, coinduction, and so on.

44) Full streams in mK.

45) Revisit Larisse's work on quantified Boolean formulas in mK.

46) Investigate quantum logic programming.

47) Implement all of miniKanren in syntax-rules (cute name:
"macroKanren").

48) Try to push the proof of mirror/the deduction theorem/etc/ farther
(skipped)

49) Write an interpreter for miniKanren.

50) Design an abstract machine for mK ("because not everybody reads
Scheme", says Dan).

51) Create a formal semantics for miniKanren.

52) Steve Johnson's problem, which we have forgotten the details of,
but it's in Will's email somewhere.

53) Implement Dan's lambda-calculus reducer algorithm which doesn't
have a beta step.  (According to Andy, it "simulates substitution by
throwing the right pieces away").

54) Further investigate the PLT-Redex style term-reducer that Will
already has in alphaKanren.  How can it be improved?

55) Or, as an alternative to 54, work with Robby to add nominal logic
to PLT Redex.

56) Implement program analyses for miniKanren (dependency analyses for
conjunction (are goals going to affect each other?) and granularity
analyses for parallel programming, for instance).

57) Handle circular terms, as in Prolog II.  With occurs-check, you
can't unify x with a term containing x, but this doesn't support circularity.

58) Work with Steve Johnson on the ERTS/golf cart autonomous vehicle
project.  The idea is that it might be interesting to do embedded
programming in a high-level language like Scheme, and in particular,
something like miniKanren might be useful for constraint solving.
"Maybe we can get the golf cart to run backwards." -- Andy

59) Raquel and Steve's security policies idea.

60) Automatic "purification" tool that can remove simple occurrences
of non-declarative and non-relational constructs from a miniKanren
program (such as one that's been ported from Prolog).

61) Create a Prolog-to-miniKanren translator.

62) Add inductive logic programming to miniKanren.  ILP combines logic
programming with machine learning; there are a number of interesting
theoretical issues, in addition to the practical applications of
machine learning.

63) Review the papers on the Curry and Mercury websites for ideas of
features to implement.

64) Review the proceedings of the major conferences and workshops from
the past 10 years (ICLP, PADL, FLOPS).

65) Investigate subsumption as an alternative to reification or
unification for tabling (skipped).

66) Add probabilistic primitives to miniKanren.

